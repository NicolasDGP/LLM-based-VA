{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f852d611-95b9-48b7-ad79-1d94d7acf48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "import requests\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa79daf-3da5-483e-af2c-397bab9e7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOGETHER_API_KEY = \"\"\n",
    "\n",
    "chat = ChatTogether(\n",
    "    together_api_key= TOGETHER_API_KEY,\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    ")\n",
    "## BIGGER MODEL\n",
    "# model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa2ce2-2a8e-418a-8394-25dd447d9f12",
   "metadata": {},
   "source": [
    "## Getting the model to do a web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a784e6c-4433-4276-9fed-d8b6034d373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if a web search is neded \n",
    "def needs_web_search(query, db_results):\n",
    "    if len(db_results )== 0:\n",
    "        return True\n",
    "\n",
    "    decision_prompt = f\"\"\"The following user query was asked: '{query}'.\n",
    "    The retrieved database results were:\n",
    "    \n",
    "    {db_results}\n",
    "    \n",
    "    Based on this, is the database context sufficient to fully answer the query?\n",
    "    Respond with 'yes' or 'no'.\"\"\"\n",
    "    \n",
    "    decision = chat.invoke(decision_prompt, max_tokens=10)\n",
    "    return \"yes\" in decision.content.lower()\n",
    "\n",
    "\n",
    "# Do the web search \n",
    "def do_web_search(query):\n",
    "    print(\"\\nWeb search is being used\")\n",
    "    api_key = \"\"\n",
    "    cse_id = \"\"\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}\"\n",
    "    response = requests.get(url)\n",
    "    results = response.json()\n",
    "    snippets = \" \".join(item[\"snippet\"] for item in results.get(\"items\", []))\n",
    "    return snippets\n",
    "\n",
    "\n",
    "# In case there's the need for a web search, the search is done and the result is added to the prompt\n",
    "def run_query(prompt):\n",
    "    entries, new_query = get_dbandentries(prompt, threshold = 0.7)\n",
    "    if needs_web_search(prompt, entries):\n",
    "        context = do_web_search(prompt)\n",
    "        prompt = \"PROMPT: \" + prompt + \"\\nCONTEXT: \" + context\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cac1ce-cbb6-43a4-b640-45a1be3a0af4",
   "metadata": {},
   "source": [
    "### Implement web search as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63591d5f-3574-49d8-a2bb-d18eea3e8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Function as a LangChain Tool\n",
    "\n",
    "web_tool = Tool(\n",
    "    name=\"do_web_search\",\n",
    "    func=run_query,\n",
    "    description=\"Use this tool to search the web for information ONLY when the query requires current, real-time information, or knowledge beyond your internal capabilities (e.g., recent events, specific URLs, current status of something). Do not use it for general knowledge questions.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814c7f7-f35a-4326-8637-b6cced096bde",
   "metadata": {},
   "source": [
    "### Implement database search as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb22af6-016c-47f6-af24-ba9fd0d9d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Tool's Functionality\n",
    "\n",
    "# Use the mps on a mac\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Import the data\n",
    "nutrition = pd.read_csv(\"epi_r.csv\").head(1000)[['title','calories','protein','fat','sodium']].dropna()\n",
    "recipes = pd.read_csv(\"dataset.csv\").head(1000)[['title','ingredients','directions']].dropna()\n",
    "\n",
    "# Combine the relevant data into a single column so it can be processed by the sentence transformer\n",
    "recipes[\"combined\"] = \"TITLE: \" + recipes[\"title\"] + \" INGREDIENTS: \" + recipes[\"ingredients\"] + \" DIRECTIONS: \" + recipes[\"directions\"]\n",
    "nutrition[\"combined\"] = \"TITLE: \" + nutrition[\"title\"]\t+ \" CALORIES: \" + nutrition[\"calories\"].astype(str) + \" PROTEIN: \" + nutrition[\"protein\"].astype(str) + \" FAT: \" + \tnutrition[\"fat\"].astype(str) + \" SODIUM: \" + nutrition[\"sodium\"].astype(str)\n",
    "\n",
    "# Use the sentence transformer model to get the embeddings\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device) # Use the all-MiniLM-L6-v2 sentence transformer model\n",
    "embeddings_recipes = embedder.encode(recipes[\"combined\"].tolist(), convert_to_numpy=True)\n",
    "embeddings_nutrition = embedder.encode(nutrition[\"combined\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "# Create the faiss index\n",
    "\n",
    "index_recipes = faiss.IndexFlatL2(embeddings_recipes.shape[1])\n",
    "index_recipes.add(embeddings_recipes)\n",
    "index_nutrition = faiss.IndexFlatL2(embeddings_nutrition.shape[1])\n",
    "index_nutrition.add(embeddings_nutrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd68edb4-b9b6-4ad9-bed3-0ef7d4c52d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary contatining the databases\n",
    "\n",
    "databases = {\n",
    "    \"recipes\": {\n",
    "        \"df\": recipes,\n",
    "        \"text\": recipes[\"combined\"],\n",
    "        \"index\": index_recipes,\n",
    "        \"embeddings\": embeddings_recipes,\n",
    "    },\n",
    "    \"nutrition\": {\n",
    "        \"df\": nutrition,\n",
    "        \"text\": nutrition[\"combined\"],\n",
    "        \"index\": index_nutrition,\n",
    "        \"embeddings\": embeddings_nutrition,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Implement a function that finds the relevant databases\n",
    "\n",
    "def find_relevant_databases(query, threshold = 0.7):\n",
    "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    relevant = []\n",
    "    for name, db in databases.items():\n",
    "        db_embeddings = db[\"embeddings\"]\n",
    "        similarity_scores = cosine_similarity(query_emb, db_embeddings)\n",
    "        max_similarity_score = np.max(similarity_scores)\n",
    "        print(\"NAME AND MAX SIMILARITY: \",name, max_similarity_score)\n",
    "        if max_similarity_score > threshold:\n",
    "            relevant.append(name)\n",
    "    return relevant, query_emb\n",
    "\n",
    "# Implement a function that takes the name of the databse, the embedded query and gets the top 3 most relecant results\n",
    "\n",
    "def get_entries(relevant, query_emb):\n",
    "    entries = []\n",
    "    context = \"CONTEXT: \"\n",
    "    for dbname in relevant:\n",
    "        if dbname == \"recipes\":\n",
    "            D, I = index_recipes.search(query_emb, k=3)\n",
    "            for idx in I[0]:\n",
    "                entry = recipes.iloc[idx]\n",
    "                context += recipes.iloc[idx][\"combined\"]\n",
    "                entries.append((idx, recipes.iloc[idx] ))\n",
    "        if dbname == \"nutrition\":\n",
    "            D, I = index_nutrition.search(query_emb, k=3)\n",
    "            for idx in I[0]:\n",
    "                entry = nutrition.iloc[idx]\n",
    "                entries.append((idx, nutrition.iloc[idx]))\n",
    "                context += nutrition.iloc[idx][\"combined\"]\n",
    "    if entries:\n",
    "        df_entries = pd.DataFrame([entry[1] for entry in entries])\n",
    "        print(\"\\nRelevant database Entries:\")\n",
    "        print(df_entries[[\"title\", \"ingredients\", \"directions\"]].reset_index(drop=True))\n",
    "    else:\n",
    "        print(\"No relevant database entries found.\")\n",
    "        \n",
    "    return entries, context\n",
    "\n",
    "# Implement the function that contains the tool's functionality\n",
    "\n",
    "def get_dbandentries(query, threshold = 0.7):\n",
    "    print(\"Database search is being used\")\n",
    "    relevant, query_emb = find_relevant_databases(query, threshold)\n",
    "    entries, context = get_entries(relevant, query_emb)\n",
    "    new_query = f\"{query}\\n\\nContext:\\n{context}\"\n",
    "    return entries, new_query\n",
    "\n",
    "\n",
    "# 2. Wrap the Function as a LangChain Tool\n",
    "\n",
    "db_tool = Tool(\n",
    "    name=\"do_db_search\",\n",
    "    func=get_dbandentries,\n",
    "    description=\"Use this tool to search the database for information. This tool should be used specifically when the user asks about macronutrient content of foods or requests recipes. Do not use it for other types of questions.\",\n",
    ")\n",
    "\n",
    "tools = [web_tool, db_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752760c-7554-42ca-a0d7-ea5a02d5645b",
   "metadata": {},
   "source": [
    "## Experimental components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274760f-ca47-4dba-ae7e-8043c64ee938",
   "metadata": {},
   "source": [
    "### Advanced prompting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9359b-3e87-4653-99af-e580542a0113",
   "metadata": {},
   "source": [
    "#### Meta prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd0a25e-92c6-4d61-a6f1-cfed68f56a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    You are an expert cooking assistant. Your job is to answer user questions with accurate and complete information related to cooking and nutrition.\n",
    "\n",
    "    Follow these steps carefully:\n",
    "    \n",
    "    1. If the question is unrelated to cooking or nutrition, politely say that you can't answer it.\n",
    "    \n",
    "    2. If the question is about a cooking recipe or nutrition:\n",
    "       a. First, use the database search tool to retrieve relevant recipes or nutritional entries.\n",
    "       b. If the database contains relevant information, use that CONTEXT to generate a full, natural-sounding answer.\n",
    "          - For recipe questions, include a complete list of ingredients and step-by-step directions.\n",
    "          - For nutrition questions, explain clearly and helpfully based on the data.\n",
    "    \n",
    "    3. If the database does not contain a relevant answer:\n",
    "       a. Use the web search tool to gather helpful information.\n",
    "       b. Write a complete, well-structured answer based on the web CONTEXT.\n",
    "          - For recipes, write a full recipe (ingredients and instructions) in conversational tone.\n",
    "          - Do not include search result links — only the helpful information.\n",
    "          - Rephrase, rewrite, and summarize where necessary to sound natural.\n",
    "    \n",
    "    4. If no useful information is found even after searching the web, politely explain that you cannot answer the question.\n",
    "    \n",
    "    Always respond clearly, naturally, and helpfully.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"), # Important for the agent's thinking process\n",
    "])\n",
    "\n",
    "# 5. Create the Agent\n",
    "agent = create_tool_calling_agent(chat, tools, prompt)\n",
    "\n",
    "# 6. Create the Agent Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False) # verbose=True shows the agent's steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2917ea38-e107-4b83-bb71-cf4909a44601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "--- Query blocked ---\n",
      "Sorry, I can only answer cooking or nutrition-related questions.\n",
      "True\n",
      "\n",
      "--- Running query: Tell me a chocolate cake recipe. ---\n",
      "Database search is being used\n",
      "NAME AND MAX SIMILARITY:  recipes 0.7449006\n",
      "NAME AND MAX SIMILARITY:  nutrition 0.6186147\n",
      "\n",
      "Relevant database Entries:\n",
      "                     title                                        ingredients  \\\n",
      "0  Favorite Chocolate Cake  [\"1 3/4 c. flour\", \"2 eggs\", \"1 tsp. baking po...   \n",
      "1          Chocolate Icing  [\"2 c. sugar\", \"1/2 c. evaporated milk\", \"3 to...   \n",
      "2               Pound Cake  [\"1 stick butter\", \"1 c. Crisco\", \"3 c. sugar\"...   \n",
      "\n",
      "                                          directions  \n",
      "0  [\"Sift all dry ingredients in a large mixing b...  \n",
      "1  [\"Mix and boil two minutes.\", \"Beat until thic...  \n",
      "2  [\"Cream butter, Crisco and sugar.\", \"Add eggs,...  \n",
      "\n",
      "--- Result ---\n",
      " Sure, here's a simple chocolate cake recipe:Ingredients:-11/2 cups all-purpose flour-11/2 cups granulated sugar-3/4 cup unsweetened cocoa powder-2 teaspoons baking powder-11/2 teaspoons baking soda-1 teaspoon salt-2 large eggs-1 cup buttermilk-1/2 cup vegetable oil-2 teaspoons vanilla extract-1 cup hot waterInstructions:1. Preheat your oven to350°F (180°C). Grease a9x13 inch baking pan.2. In a large mixing bowl, whisk together the flour, sugar, cocoa powder, baking powder, baking soda, and salt.3. Add the eggs, buttermilk, vegetable oil, and vanilla extract to the dry ingredients. Mix until well combined.4. Slowly pour in the hot water and mix until the batter is smooth.5. Pour the batter into the prepared baking pan and smooth the top with a spatula.6. Bake for30-35 minutes, or until a toothpick inserted into the center of the cake comes out clean.7. Let the cake cool in the pan for10 minutes before transferring it to a wire rack to cool completely.\n",
      "\n",
      "Enjoy your delicious chocolate cake!\n",
      "True\n",
      "\n",
      "--- Running query: How to make Frikadeller? ---\n",
      "Database search is being used\n",
      "NAME AND MAX SIMILARITY:  recipes 0.5491195\n",
      "NAME AND MAX SIMILARITY:  nutrition 0.5044667\n",
      "No relevant database entries found.\n",
      "\n",
      "Web search is being used\n",
      "\n",
      "--- Result ---\n",
      " Frikadeller is a traditional Danish dish made with a mixture of ground beef and pork, onion, breadcrumbs, flour, eggs, salt, pepper, nutmeg, garlic, and sage leaves. The recipe typically involves mixing the ingredients together and then slowly adding in half & half until the mixture forms a smooth, creamy consistency. The mixture is then formed into small, round balls and fried until golden brown. Frikadeller is often served with a creamy gravy and is a popular dish in Denmark.\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the query is cooking or nutrition related using the model\n",
    "\n",
    "def is_cooking_related(query):\n",
    "    system_msg = SystemMessage(content=\"You are a helpful assistant. Determine if the following question is related to cooking or nutrition. Reply only 'yes' if the question is related or 'no' if the question is not related.\")\n",
    "    user_msg = HumanMessage(content=query)\n",
    "\n",
    "    classification = chat.invoke([system_msg, user_msg])\n",
    "    return \"yes\" in classification.content.strip().lower()\n",
    "\n",
    "def run_query_with_filter(query):\n",
    "    print(is_cooking_related(query))\n",
    "    if is_cooking_related(query):\n",
    "        print(f\"\\n--- Running query: {query} ---\")\n",
    "        result = agent_executor.invoke({\"input\": query})\n",
    "        print(\"\\n--- Result ---\")\n",
    "        print(result['output'])\n",
    "    else:\n",
    "        print(f\"\\n--- Query blocked ---\\nSorry, I can only answer cooking or nutrition-related questions.\")\n",
    "\n",
    "# Example queries\n",
    "run_query_with_filter(\"What is the capital of France?\")\n",
    "run_query_with_filter(\"Tell me a chocolate cake recipe.\")\n",
    "run_query_with_filter(\"How to make Frikadeller?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38af97e8-0ee0-4410-ad3b-3e95b8661bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME AND MAX SIMILARITY:  recipes 0.55985504\n",
      "NAME AND MAX SIMILARITY:  nutrition 0.92988193\n"
     ]
    }
   ],
   "source": [
    "query = \"Give calories, protein and fat for Boudin Blanc Terrine with Red Onion Confit\"\n",
    "bd = find_relevant_databases(query, threshold = 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
